\documentclass[unicode,11pt,a4paper,oneside,numbers=endperiod,openany]{scrartcl}

% Required package
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{matlab-prettifier}
\usepackage{float}
\usepackage[export]{adjustbox}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{amsthm} % math theorems
\usepackage{ifthen}
\usepackage{physics} % responsive norm, abs, ...
\usepackage{algorithm}
\usepackage{algpseudocode}


\renewcommand{\thesubsection}{\arabic{subsection}}

% 1: command name, 2: Title, 3: subtitle, 4: label, 5: content
\newcommand{\mytheorem}[5]{\newtheorem*{#1}{#2} \begin{#1}[#3]\label{#4} #5 \end{#1}}

% 1: if numbered equation, 2: label, 3: content
\newcommand{\myex}[3]{
    \ifthenelse{\equal{#1}{true}}{
        \begin{equation} \label{#2} \begin{aligned} #3 \end{aligned} \end{equation}
    }{
        \begin{equation*} \label{#2} \begin{aligned} #3 \end{aligned} \end{equation*}
    }
}

% vector shortcut
\newcommand{\myvec}[1]{\begin{bmatrix} #1 \end{bmatrix}}

% 1: caption, 2: label, 3: trim, 4: figure within figures folder
\newcommand{\myfigure}[4]{
    \begin{figure}[htbp]
    \centering
    \caption{#1}
    \label{#2}
    \includegraphics[width=\paperwidth, trim=#3]{./figures/#4}
    \end{figure}
}

\def\ex2f{f(\mathbf{x}^*)}

\input{assignment.sty}
\begin{document}

\setassignment
\setduedate{Monday, 3 June 2024, 12:00 AM}

\serieheader
{Optimization Methods}
{2024}
{\textbf{Student:} Jeferson Morales Mariciano \\\\}
{\textbf{Discussed with:} }
{Assignment 4}{}
\newline

%----------------------------------------------------------------------------------
\section{Exercise (20/100)}

Consider the quadratic function \( f: \mathbb{R}^2 \rightarrow \mathbb{R} \) defined as:

\myex{true}{eq:ex1-f}{
    f(\mathbf{x}) = 7 x^2 + 4 xy + y^2
}

\noindent where \( \mathbf{x} = (x, y)^T \).

\begin{enumerate}
    \item Write this function in canonical form, i.e.
          \( f( \mathbf{x} ) = \frac{1}{2} \mathbf{x}^T \mathbf{A} \mathbf{x} + \mathbf{b}^T \mathbf{x} + c \),
          where \( A \) is a symmetric matrix.

    \item Describe briefly how the Conjugate Gradient (CG) Method works
          and discuss whether it is suitable to minimize \( f \) from equation \ref{eq:ex1-f}.
          Explain your reasoning in detail (max. 30 lines).
\end{enumerate}

\subsection{Answer}

The function written in canonical form correspond to:

\myex{false}{eq:ex1-f-quadratic}{
    f( \mathbf{x} )
    &= 7 x^2 + 4 xy + y^2 \\
    &= \myvec{7x + 2y & 2x + y} \myvec{x \\ y} \\
    &= \myvec{x & y} \myvec{7 & 2 \\ 2 & 1} \myvec{x \\ y} \\
    &= \frac{1}{2} \myvec{x & y} \myvec{14 & 4 \\ 4 & 2} \myvec{x \\ y} \\
    &= \frac{1}{2} \mathbf{x}^T \mathbf{A} \mathbf{x}
}

\noindent With \( \mathbf{b} = \mathbf{0}, \; c = 0 \),
and \( A \) being clearly a symmetric matrix:

\myex{false}{}{
    \mathbf{A} = \myvec{14 & 4 \\ 4 & 2}
}

\noindent Let's verify if \( A \) is positive define as required by the quadratic form:

\myex{false}{}{
    \det \left( \lambda I - \mathbf{A} \right)
    &= \mdet{\lambda - 14 & -4 \\ -4 & \lambda - 2} \\
    &= \lambda^2 - 16 + 12 \\
    &\Rightarrow \lambda_{1,2} = 8 \pm 2 \sqrt{13} > 0
}

\noindent Finally, since all eigenvalues are positive, \( \mathbf{A} \) is SPD.

\subsection{Answer}

The CG method is an iterative algorithm for solving a linear system of equations
\( A x = b \) where \( A \in \mathbb{R}^{n \times n} \) is a symmetric positive definite matrix.
% with specific application to the minimization of quadratic functions
whose Hessian matrix is symmetric and \textbf{positive definite}.
The performance of the linear CG method is determined
by the \textbf{distribution of the eigenvalues} of the coefficient matrix,
which are 2 so is a good candidate already.
The CG method is appropriate and effective for minimizing the quadratic function.


%----------------------------------------------------------------------------------
%----------------------------------------------------------------------------------
%----------------------------------------------------------------------------------
\section{Exercise (20/100)}

Consider the following constrained minimization problem for \( \mathbf{x} = (x, y, z)^T \)

\myex{true}{eq:ex2-min-f}{
    &\min_{\mathbf{x}} f(\mathbf{x}) := -3x^2 + y^2 + 2z^2 + 2(x + y + z) \\
    &\text{subject to} \quad c(\mathbf{x}) = x^2 + y^2 + z^2 - 1 = 0
}

\noindent Write down the Lagrangian function
and derive the KKT conditions for (\ref{eq:ex2-min-f}).

\subsection*{Answer}

The constrained optimization problem can be written as:

\myex{true}{eq:ex2-def-f-constrained}{
    \min_{\mathbf{x} \in {\mathbb{R}^n}} f(\mathbf{x})
    \quad \text{subject to}
    \quad
    \begin{cases}
        c_i (\mathbf{x}) = 0 \quad i \in \mathcal{E}    \\
        c_i (\mathbf{x}) \geq 0 \quad i \in \mathcal{I} \\
    \end{cases}
}

\noindent where the \textbf{objective function} \( f \)
and the \textbf{constraint functions} on the variables \( c_i \)
are all smooth and real-valued defined
on a subset of \( \mathbb{R}^n \).
The problem defines two finite sets of indices:
\( \mathcal{I} \) for the \textbf{equality constraints}
and \( \mathcal{E} \) for the \textbf{inequality contraints}.
In addition, the set of points \( \mathbf{x} \) that satisfy the constraints
is defined as the \textbf{feasible region} \( \Omega \):

\myex{true}{eq:ex2-def-feasible-region}{
    \Omega = \{ \mathbf{x} \mid c_i ( \mathbf{x} ) = 0, \; i \in \mathcal{E};
    \; c_i ( \mathbf{x} ) \geq 0, \; i \in \mathcal{I} \}
}

\noindent Allowing to coincisely write the constrained optimization problem as:

\myex{true}{eq:ex2-def-f-constrained-coincise}{
    \min_{\mathbf{x} \in \Omega} f(\mathbf{x})
}

\noindent Then, the \textbf{active set} \( \mathcal{A}( \mathbf{x} ) \)
at any feasible \( \mathbf{x} \) consists of the equality constraints indices from
\( \mathcal{E} \) together with the indices of the inequality constraints \( i \)
for which \( c_i ( \mathbf{x} ) = 0 \):

\myex{true}{eq:ex2-def-active-set}{
    \mathcal{A}( \mathbf{x} ) = \mathcal{E} \cup \{ i \in \mathcal{I} \mid c_i ( \mathbf{x} ) = 0 \}
}

So, at a feasible point \( \mathbf{x} \), the inequality constraint \( i \in \mathcal{I} \)
is said to be active if \( c_i ( \mathbf{x} ) = 0 \)
and inactive if the strict inequality \( c_i ( \mathbf{x} ) > 0 \) is satisfied.

\noindent Assuming a single equality scenario part of the active set,
at the solution \( \mathbf{x}^* \),
the constraint normal \( \nabla c_1 ( \mathbf{x}^* ) \) is parallel to
\( \nabla f ( \mathbf{x}^* ) \), meaning that there is a scalar \( \lambda_1^* \)
called \textbf{Lagrangian multiplier} such that:

\myex{true}{eq:ex2-def-lagrangian-multiplier}{
    \nabla f ( \mathbf{x}^* ) = \lambda_1^* \nabla c_1 ( \mathbf{x}^* )
}

\noindent Finally, the \textbf{Langragian function} and its gradient
for the general problem are defined as:

\myex{true}{eq:ex2-lagrangian}{
    \mathcal{L} (\mathbf{x}, \lambda)
    &= f(\mathbf{x}) - \sum_{i \in \mathcal{E} \cup \mathcal{I}} \lambda_i c_i(\mathbf{x}) \\
    \nabla_x \mathcal{L} (\mathbf{x}, \lambda)
    &= \nabla f(\mathbf{x})
    - \sum_{i \in \mathcal{E} \cup \mathcal{I}} \lambda_i \nabla c_i(\mathbf{x})
}

\noindent If assuming a single equality constraint scenario part of the active set,
note that
\( \nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \lambda_1)
= \nabla f( \mathbf{x} ) - \lambda_1 \nabla c_1 ( \mathbf{x} )\),
allowing to write the condition (\ref{eq:ex2-def-lagrangian-multiplier})
equivalently as follows:

\myex{true}{eq:ex2-lagrangian-gradient-simple}{
    \text{at solution } \mathbf{x}^*, \; \exists \; \lambda_1^* : \;
    \nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}^*, \lambda_1^*) = \mathbf{0}
}

\noindent This observation suggests that
we can search for solutions of the equality-constrained problem (\ref{eq:ex2-min-f})
by seeking stationary points of the Lagrangian function.
The conditions (\ref{eq:ex2-def-lagrangian-multiplier})
and (\ref{eq:ex2-lagrangian-gradient-simple})
are equivalent
and necessary conditions for an optimal solution of the problem (\ref{eq:ex2-min-f}),
but clearly not sufficient.

An important constraint qualification condition is \textbf{LICQ}:
given the point \( \mathbf{x} \) and the active set \( \mathcal{A}( \mathbf{x} ) \)
defined in (\ref{eq:ex2-def-active-set}),
we say that the Linear Independence Contraint Qualification (LICQ) holds
if the set of active constraint gradients
\( \{ \nabla c_i ( \mathbf{x} ) \mid i \in \mathcal{A}( \mathbf{x} ) \} \)
is linearly independent.
In general, if LICQ holds, none of the active constraints gradients can be zero.

The following necessary conditions defined are called first-order conditions
because they are concerned with properties of the gradients (first-derivative vectors)
of the objective and constraint functions.
\textbf{First-Order Necessary Conditions}:
suppose that \( \mathbf{x}^* \) is a local solution of (\ref{eq:ex2-min-f}),
that the functions \( f \) and \( c_i \) in (\ref{eq:ex2-min-f})
are continuously differentiable, and that the LICQ holds at \( \mathbf{x}^* \).
Then there is a Lagrange multiplier vector \( \lambda^* \),
with components \( \lambda_i^*, \; i \in \mathcal{E} \cup \mathcal{I} \),
such that the following conditions are satisfied at \( (\mathbf{x}^*, \lambda^*) \):

\myex{true}{eq:ex2-kkt}{
    \nabla_{\mathbf{x}} \mathcal{L} (\mathbf{x}^*, \lambda^*) &= \mathbf{0} \\
    c_i( \mathbf{x}^* ) &= \mathbf{0} \quad \forall i \in \mathcal{E} \\
    c_i( \mathbf{x}^* ) &\geq \mathbf{0} \quad \forall i \in \mathcal{I} \\
    \lambda_i^* &\geq 0 \quad \forall i \in \mathcal{I} \\
    \lambda_i^* c_i( \mathbf{x}^* ) &= \mathbf{0} \quad \forall i \in \mathcal{E} \cup \mathcal{I}
    \quad \text{(complementary conditions)}
}

The conditions (\ref{eq:ex2-kkt}) are often known as the Karush-Kuhn-Tucker conditions,
or \textbf{KKT conditions} for short.
The last row in (\ref{eq:ex2-kkt}) contains the complementary conditions,
they imply that either constraint \( i \) is active or \( \lambda_i^* = 0 \),
or possibly both.
In particular, the Lagrange multipliers corresponding to inactive inequality constraints are zero,
we can omit the terms for indices \( i \notin \mathcal{A}( \mathbf{x}^* ) \)
from the first condition in (\ref{eq:ex2-kkt}) and rewrite it as:

\myex{true}{eq:ex2-computed-complementary-condition}{
    \mathbf{0}
    = \nabla_{\mathbf{x}} \mathcal{L} (\mathbf{x}^*, \lambda^*)
    = \nabla f ( \mathbf{x}^* )
    - \sum_{i \in \mathcal{A}( \mathbf{x}^* )} \lambda_i^* \nabla c_i ( \mathbf{x}^* )
}

\noindent The derived Lagrangian function for the problem (\ref{eq:ex2-min-f}) is:

\myex{false}{}{
    \mathcal{L} (\mathbf{x}, \lambda)
    &= f(\mathbf{x}) - \sum_{i \in \mathcal{E} \cup \mathcal{I}} \lambda_i c_i(\mathbf{x})
    \qquad \mathcal{E} = \{ 1 \}, \; \mathcal{I} = \emptyset \\
    &= f(\mathbf{x}) - \lambda c (\mathbf{x}) \\
    &= -3x^2 + y^2 + 2z^2 + 2(x + y + z) - \lambda \left( x^2 + y^2 + z^2 - 1 \right) \\
    &= (-3 - \lambda) x^2 + (1 - \lambda) y^2 + (2 - \lambda) z^2 + 2(x + y + z) + \lambda
}

\noindent Let \( \mathbf{x}^* = \myvec{x^*, y^*, z^*}^T \) be a local solution,
then the derived KKT conditions are:

\myex{false}{}{
    \nabla \ex2f = \myvec{-6 x^* + 2 \\ 2 y^* + 2 \\ 4 z^* + 2},
    \quad \nabla c = \myvec{2 x^* \\ 2 y^* \\ 2 z^*} \\
    \nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}^*, \lambda^*) = \mathbf{0}
    \Rightarrow
    \myvec{
        -6 x^* + 2 - 2 \lambda^* x^* \\
        2 y^* + 2 - 2 \lambda^* y^* \\
        4 z^* + 2 - 2 \lambda^* z^*
    }
    = \myvec{0 \\ 0 \\ 0} \\
    c(\mathbf{x}^*) = 0
    \Rightarrow
    (x^*)^2 + (y^*)^2 + (z^*)^2 - 1 = 0
    \\
    \lambda^* c(\mathbf{x}^*) = 0
    \Rightarrow
    \lambda^* \left( (x^*)^2 + (y^*)^2 + (z^*)^2 - 1 \right) = 0
}

Note that if equality condition \( c(\mathbf{x}^*) = 0 \) holds,
then condition \( \lambda^* c(\mathbf{x}^*) = 0 \) is also satisfied.

%----------------------------------------------------------------------------------
%----------------------------------------------------------------------------------
%----------------------------------------------------------------------------------
\section{Exercise (60/100)}

\begin{enumerate}
    \item Read the chapter on Simplex method, in particular the section 13.3 The Simplex Method,
          in Numerical Optimization, Nocedal and Wright.
          Explain how the method works, with a particular attention to the search direction.

    \item Consider the following contrained minimization problem,
          \( \mathbf{x} = (x_1, x_2)^T \);

          \myex{true}{eq:ex3-min-f}{
              \min_{\mathbf{x}} f(\mathbf{x}) := 4x_1 + 3x_2
          }

          subect to:

          \myex{true}{eq:ex3-constraints}{
              6 - 2x_1 - 3x_2 \geq 0 \\
              3 + 3x_1 - 2x_2 \geq 0 \\
              5 - 2x_2 \geq 0 \\
              4 - 2x_1 - x_2 \geq 0 \\
              x_2 \geq 0 \\
              x_1 \geq 0 \\
          }

          \begin{enumerate}
              \item Sketch the feasible region for this problem.

              \item Which are the basic feasible points of the problem \ref{eq:ex3-min-f}?
                    Compute them by hand using the geometrical interpretation
                    and find the optimal point \( \mathbf{x^*} \)
                    that minimizes \( f \) subject to the constraints.

              \item Prove that the first order necessary conditions holds for the optimal point.
          \end{enumerate}
\end{enumerate}

\subsection{Answer}

The Simplex method is \dots

The algorithm works by \dots

Algorithm block \dots

The search direction \dots

\subsection{Answer}

\subsection*{a)}

The sketch of the feasible region in Figure \ref{fig:feasible-region}
was done with an online tool using geogebra as backend.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{./figures/ex3-feasible-region.png}
    \caption{Feasible region for the problem \ref{eq:ex3-min-f} and \ref{eq:ex3-constraints}}
    \label{fig:feasible-region}
\end{figure}

\subsection*{b)}
\subsection*{c)}

\end{document}
